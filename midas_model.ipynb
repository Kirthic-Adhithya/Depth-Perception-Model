{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba46eabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\kirth/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "Using cache found in C:\\Users\\kirth/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 250 real KITTI pairs.\n",
      "[INFO] Found 2706 pseudo-labeled pairs.\n",
      "[INFO] Using 2956 imageâ€“depth pairs total.\n",
      "[INFO] Using 2364 imageâ€“depth pairs for training.\n",
      "[INFO] Using 592 imageâ€“depth pairs for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1182/1182 [01:47<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Training Loss: 0.5603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1182/1182 [01:49<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Training Loss: 0.2635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1182/1182 [01:51<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Training Loss: 0.2493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:40<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluation Metrics:\n",
      "MAE:  0.4510\n",
      "MSE:  0.2528\n",
      "RMSE: 0.5027\n",
      "SSIM: 0.3223\n",
      "âœ… Fine-tuned MiDaS model and predictions saved to 'outputs/'\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# âœ… Final Stable MiDaS Fine-Tuning Script for KITTI-like Depth Data\n",
    "# ================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from data_loader import get_data_loaders\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim_metric\n",
    "\n",
    "# ----------------------------\n",
    "# Setup\n",
    "# ----------------------------\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Load MiDaS & Transforms\n",
    "# ----------------------------\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Hybrid\")\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "midas_transform = midas_transforms.dpt_transform  # preprocessing for DPT_Hybrid\n",
    "\n",
    "# ----------------------------\n",
    "# Modify model for fine-tuning\n",
    "# ----------------------------\n",
    "for param in midas.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final output layer for single-channel depth prediction\n",
    "midas.scratch.output_conv = nn.Conv2d(256, 1, kernel_size=3, stride=1, padding=1)\n",
    "midas.to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# Loss & Optimizer\n",
    "# ----------------------------\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, midas.parameters()), lr=1e-4)\n",
    "\n",
    "# ----------------------------\n",
    "# Load Data\n",
    "# ----------------------------\n",
    "train_loader, val_loader = get_data_loaders('data', pseudo_dir='pseudo_data', batch_size=2)\n",
    "\n",
    "# ----------------------------\n",
    "# Training Loop\n",
    "# ----------------------------\n",
    "num_epochs = 3\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    midas.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for imgs, depths in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        imgs, depths = imgs.to(device), depths.to(device)\n",
    "\n",
    "        # Apply MiDaS transform to each image\n",
    "        batch_imgs = []\n",
    "        for img in imgs:\n",
    "            np_img = img.permute(1, 2, 0).cpu().numpy()  # (H, W, 3)\n",
    "            t = midas_transform(np_img)\n",
    "            if isinstance(t, dict):\n",
    "                t = t[\"image\"]\n",
    "            batch_imgs.append(t)\n",
    "\n",
    "        imgs = torch.stack(batch_imgs).to(device)\n",
    "        if imgs.dim() == 5:\n",
    "            imgs = imgs.squeeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = midas(imgs)\n",
    "\n",
    "        # --- Fix output shape ---\n",
    "        if preds.ndim == 3:  # [N, H, W]\n",
    "            preds = preds.unsqueeze(1)\n",
    "        elif preds.ndim == 2:  # single image [H, W]\n",
    "            preds = preds.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # --- Match depth map size ---\n",
    "        preds = torch.nn.functional.interpolate(\n",
    "            preds, size=depths.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "\n",
    "        loss = criterion(preds, depths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Training Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation\n",
    "# ----------------------------\n",
    "midas.eval()\n",
    "predictions, ground_truths = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, depths in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        imgs, depths = imgs.to(device), depths.to(device)\n",
    "\n",
    "        batch_imgs = []\n",
    "        for img in imgs:\n",
    "            np_img = img.permute(1, 2, 0).cpu().numpy()\n",
    "            t = midas_transform(np_img)\n",
    "            if isinstance(t, dict):\n",
    "                t = t[\"image\"]\n",
    "            batch_imgs.append(t)\n",
    "\n",
    "        imgs = torch.stack(batch_imgs).to(device)\n",
    "        if imgs.dim() == 5:\n",
    "            imgs = imgs.squeeze(1)\n",
    "\n",
    "        preds = midas(imgs)\n",
    "        if preds.ndim == 3:\n",
    "            preds = preds.unsqueeze(1)\n",
    "\n",
    "        preds = torch.nn.functional.interpolate(\n",
    "            preds, size=depths.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "\n",
    "        predictions.append(preds.cpu())\n",
    "        ground_truths.append(depths.cpu())\n",
    "\n",
    "predictions = torch.cat(predictions)\n",
    "ground_truths = torch.cat(ground_truths)\n",
    "\n",
    "# ----------------------------\n",
    "# Compute Evaluation Metrics\n",
    "# ----------------------------\n",
    "mae = torch.mean(torch.abs(predictions - ground_truths)).item()\n",
    "mse = torch.mean((predictions - ground_truths) ** 2).item()\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Convert to numpy for SSIM\n",
    "pred_np = predictions.squeeze().numpy()\n",
    "gt_np = ground_truths.squeeze().numpy()\n",
    "if pred_np.ndim == 3:  # handle batch\n",
    "    ssim_scores = [ssim_metric(p, g, data_range=g.max() - g.min()) for p, g in zip(pred_np, gt_np)]\n",
    "    mean_ssim = np.mean(ssim_scores)\n",
    "else:\n",
    "    mean_ssim = ssim_metric(pred_np, gt_np, data_range=gt_np.max() - gt_np.min())\n",
    "\n",
    "print(\"\\nðŸ“Š Evaluation Metrics:\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"MSE:  {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"SSIM: {mean_ssim:.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save Outputs\n",
    "# ----------------------------\n",
    "torch.save(midas.state_dict(), \"outputs/midas_finetuned.pth\")\n",
    "torch.save({\n",
    "    \"predictions\": predictions,\n",
    "    \"ground_truths\": ground_truths\n",
    "}, \"outputs/midas_predictions.pt\")\n",
    "\n",
    "print(\"âœ… Fine-tuned MiDaS model and predictions saved to 'outputs/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fad39a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirth\\AppData\\Local\\Temp\\ipykernel_13184\\2219870245.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(\"outputs/midas_predictions.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 592 samples for visualization.\n",
      "âœ… Saved visual comparisons in 'outputs/visuals/'\n",
      "âœ… Saved depth distribution plot as 'depth_distribution.png'\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Visualization Script for MiDaS Fine-Tuned Model\n",
    "# ================================================================\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# ----------------------------\n",
    "# Load Saved Predictions\n",
    "# ----------------------------\n",
    "data = torch.load(\"outputs/midas_predictions.pt\")\n",
    "predictions = data[\"predictions\"].squeeze().numpy()\n",
    "ground_truths = data[\"ground_truths\"].squeeze().numpy()\n",
    "\n",
    "# Make sure both have same number of samples\n",
    "num_samples = min(len(predictions), len(ground_truths))\n",
    "print(f\"Loaded {num_samples} samples for visualization.\")\n",
    "\n",
    "os.makedirs(\"outputs/visuals\", exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Utility Function: Normalize for display\n",
    "# ----------------------------\n",
    "def normalize_depth(depth):\n",
    "    depth = depth - np.min(depth)\n",
    "    depth = depth / (np.max(depth) + 1e-8)\n",
    "    return depth\n",
    "\n",
    "# ----------------------------\n",
    "# Plot a few samples\n",
    "# ----------------------------\n",
    "for i in range(min(5, num_samples)):\n",
    "    pred = normalize_depth(predictions[i])\n",
    "    gt = normalize_depth(ground_truths[i])\n",
    "    \n",
    "    # Compute SSIM for display\n",
    "    ssim_score = ssim(pred, gt, data_range=gt.max() - gt.min())\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(pred, cmap='inferno')\n",
    "    plt.title(f\"Predicted Depth (SSIM={ssim_score:.3f})\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(gt, cmap='inferno')\n",
    "    plt.title(\"Ground Truth Depth\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"outputs/visuals/depth_compare_{i}.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"âœ… Saved visual comparisons in 'outputs/visuals/'\")\n",
    "\n",
    "# ----------------------------\n",
    "# Optional: Histogram of depth values\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(predictions.flatten(), bins=50, alpha=0.6, label=\"Predicted\")\n",
    "plt.hist(ground_truths.flatten(), bins=50, alpha=0.6, label=\"Ground Truth\")\n",
    "plt.title(\"Depth Value Distribution\")\n",
    "plt.xlabel(\"Normalized Depth\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/visuals/depth_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"âœ… Saved depth distribution plot as 'depth_distribution.png'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
